{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Maximum Emitter Base Voltage from Digikey Datasheets\n",
    "\n",
    "This Jupyter Notebook will begin extracting additional relations from transistors (`eb_v_max`, `c_current_max`, `dev_dissipation`, `dc_gain_min`).\n",
    "\n",
    "Sarting with the `max_emitter_base_voltage` as shown below.\n",
    "\n",
    "# Phase 1: KBC Initialization\n",
    "\n",
    "Created a new database named `eb_v_max` for extracting the maximum ratings for emitter - base voltage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "logging.basicConfig(stream=sys.stdout, format='[%(levelname)s] %(name)s - %(message)s')\n",
    "log = logging.getLogger('fonduer')\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "PARALLEL = 12 # changed to 12 for watchog.stanford.edu\n",
    "ATTRIBUTE = \"eb_v_max\"\n",
    "conn_string = 'postgresql://nchiang:postgres@localhost:5432/' + ATTRIBUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Parsing and Transforming the Input Documents into Unified Data Models\n",
    "\n",
    "We first initialize a `Meta` object, which manages the connection to the database automatically, and enables us to save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.meta - Connecting user:nchiang to localhost:5432/eb_v_max\n",
      "[INFO] fonduer.meta - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from fonduer import Meta\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring an `HTMLDocPreprocessor`\n",
    "We start by setting the paths to where our documents are stored, and defining a `HTMLDocPreprocessor` to read in the documents found in the specified paths. `max_docs` specified the number of documents to parse.\n",
    "\n",
    "In the `transistor_dataset` that was downloaded as per Luke's instruction, there are 123 HTML files in `/dev/html`, 76 HTML files in `/test/html`, 2745 HTML files in `/train_digikey/html`. \n",
    "\n",
    "In order to, however, maintain consistency with and use previously defined gold labels, this test run is parsing the hardware tutorial's 100-pdf-long dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.parser.preprocessors import HTMLDocPreprocessor\n",
    "from fonduer.parser import Parser\n",
    "\n",
    "docs_path = 'data/html/'\n",
    "pdf_path = 'data/pdf/'\n",
    "\n",
    "max_docs = 100\n",
    "doc_preprocessor = HTMLDocPreprocessor(docs_path, max_docs=max_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a `Parser`\n",
    "Next, we configure a `Parser`, which serves as our `CorpusParser` for PDF documents. We use [spaCy](https://spacy.io/) as a preprocessing tool to split our documents into sentences and tokens, and to provide annotations such as part-of-speech tags and dependency parse structures for these sentences. In addition, we can specify which modality information to include in the unified data model for each document. Below, we enable all modality information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b5e46c023c4e2b8d9dfce5b5a87f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 16.5 s, sys: 1.15 s, total: 17.6 s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "corpus_parser = Parser(session, parallelism=PARALLEL, structural=True, lingual=True, visual=True, pdf_path=pdf_path)\n",
    "%time corpus_parser.apply(doc_preprocessor, pdf_path=pdf_path, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to ensure consistency in document numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 100\n",
      "Sentences: 43803\n"
     ]
    }
   ],
   "source": [
    "from fonduer.parser.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dividing the Corpus into Test and Train\n",
    "\n",
    "We'll split the documents 80/10/10 into train/dev/test splits. Note that here we do this in a non-random order to preserve the consistency in the tutorial, and we reference the splits by 0/1/2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['112823',\n",
      " 'BC546A_Series_B14-521026',\n",
      " 'CSEMS03485-1',\n",
      " 'FAIRS19194-1',\n",
      " 'LTSCS02910-1',\n",
      " 'PHGLS20267-1',\n",
      " 'DISES00616-1',\n",
      " 'PHGLS19500-1',\n",
      " 'CSEMS02742-1',\n",
      " 'LITES00690-1',\n",
      " 'DISES00490-1',\n",
      " 'CSEMS05383-1',\n",
      " 'LTSCS02920-1',\n",
      " 'CSEMS05382-1',\n",
      " 'BC182-D',\n",
      " 'DISES00645-1',\n",
      " 'LTSCS02912-1',\n",
      " 'MCCCS08818-1',\n",
      " 'BC182',\n",
      " 'DISES00192-1',\n",
      " 'BournsInc_TIP152S',\n",
      " 'MOTOS04796-1',\n",
      " 'MicroCommercialCo_2N3904AP',\n",
      " 'MCCCS08610-1',\n",
      " 'BC337',\n",
      " 'DISES00189-1',\n",
      " 'BournsInc_BD246BS',\n",
      " 'FAIRS25065-1',\n",
      " 'ONSemiconductor_MMBT6521LT1',\n",
      " '2N6427',\n",
      " 'DISES00242-1',\n",
      " 'CentralSemiconductorCorp_CENU45',\n",
      " 'LITES00424-1',\n",
      " 'NXPUSAInc_PBSS5360PASX',\n",
      " '2N6426-D',\n",
      " 'CentralSemiconductorCorp_2N4013',\n",
      " 'KECCS05435-1',\n",
      " 'MOTOS03160-1',\n",
      " 'LITES00689-1',\n",
      " 'DIODS00215-1',\n",
      " 'CentralSemiconductorCorp_CXT4033TR',\n",
      " 'AUKCS04635-1',\n",
      " 'LITES00686-1',\n",
      " 'DISES00023-1',\n",
      " 'MOTOS03189-1',\n",
      " 'CentralSemiconductorCorp_CMPT5401ETR',\n",
      " 'Infineon-BC857SERIES_BC858SERIES_BC859SERIES_BC860SERIES-DS-v01_01-en',\n",
      " 'DIODS13249-1',\n",
      " 'MOTOS04676-1',\n",
      " 'MCCCS08984-1',\n",
      " 'Infineon-BC817KSERIES_BC818KSERIES-DS-v01_01-en',\n",
      " 'MINDS00015-1',\n",
      " 'JCSTS01155-1',\n",
      " 'DiodesIncorporated_ZTX789ASTZ',\n",
      " 'BC547',\n",
      " '2N3906-D',\n",
      " 'MMMCS17742-1',\n",
      " '2N3906',\n",
      " 'INFNS19372-1',\n",
      " 'DiodesIncorporated_ZXT690BKTC',\n",
      " 'BC818-40LT1-D',\n",
      " 'MMBT3904',\n",
      " 'KECCS03676-1',\n",
      " '2N4124',\n",
      " 'DiodesIncorporated_ZTX953STZ',\n",
      " 'BC818',\n",
      " 'DiodesIncorporated_FZT651TC',\n",
      " 'MCCCS09540-1',\n",
      " 'DiodesIncorporated_2DD26527',\n",
      " 'MicroCommercialCo_TIP29ABP',\n",
      " '2N4123-D',\n",
      " 'MicrosemiCorporation_2N2484UB',\n",
      " 'BC546',\n",
      " 'MCCCS09741-1',\n",
      " 'ONSMS04099-1',\n",
      " 'FairchildSemiconductor_KSC2310YTA',\n",
      " 'DiodesIncorporated_ZTX688BSTZ',\n",
      " 'BC337-D',\n",
      " 'DiodesIncorporated_FCX491ATA',\n",
      " 'BC546-BC548C(TO-92)']\n"
     ]
    }
   ],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "splits = (0.8, 0.9)\n",
    "data = [(doc.name, doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if i < splits[0] * ld:\n",
    "        train_docs.add(doc)\n",
    "    elif i < splits[1] * ld:\n",
    "        dev_docs.add(doc)\n",
    "    else:\n",
    "        test_docs.add(doc)\n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Mention Extraction, Candidate Extraction Multimodal Featurization\n",
    "\n",
    "Given the unified data model from Phase 1, `Fonduer` extracts relation\n",
    "candidates based on user-provided **matchers** and **throttlers**. Then,\n",
    "`Fonduer` leverages the multimodality information captured in the unified data\n",
    "model to provide multimodal features for each candidate.\n",
    "\n",
    "## 2.1 Mention Extraction\n",
    "\n",
    "We first start by defining and naming our two `mention`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "\n",
    "Part = mention_subclass(\"Part\")\n",
    "EBVoltage = mention_subclass(\"EBVoltage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transistor Part Number Matchers\n",
    "\n",
    "Previously defined transistor part number matchers as found in the `maximum_storage_tempature.ipynb` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.matchers import RegexMatchSpan, DictionaryMatch, LambdaFunctionMatcher, Intersect, Union\n",
    "\n",
    "### Transistor Naming Conventions as Regular Expressions ###\n",
    "eeca_rgx = r'([ABC][A-Z][WXYZ]?[0-9]{3,5}(?:[A-Z]){0,5}[0-9]?[A-Z]?(?:-[A-Z0-9]{1,7})?(?:[-][A-Z0-9]{1,2})?(?:\\/DG)?)'\n",
    "jedec_rgx = r'(2N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jis_rgx = r'(2S[ABCDEFGHJKMQRSTVZ]{1}[\\d]{2,4})'\n",
    "others_rgx = r'((?:NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|ZXT|TIS|TIPL|DTC|MMBT|SMMBT|PZT|FZT|STD|BUV|PBSS|KSC|CXT|FCX|CMPT){1}[\\d]{2,4}[A-Z]{0,5}(?:-[A-Z0-9]{0,6})?(?:[-][A-Z0-9]{0,1})?)'\n",
    "\n",
    "part_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "part_rgx_matcher = RegexMatchSpan(rgx=part_rgx, longest_match_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create a matcher from a dictionary of known part numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_digikey_parts_set(path):\n",
    "    \"\"\"\n",
    "    Reads in the digikey part dictionary and yeilds each part.\n",
    "    \"\"\"\n",
    "    all_parts = set()\n",
    "    with open(path, \"r\") as csvinput:\n",
    "        reader = csv.reader(csvinput)\n",
    "        for line in reader:\n",
    "            (part, url) = line\n",
    "            all_parts.add(part)\n",
    "    return all_parts\n",
    "\n",
    "### Dictionary of known transistor parts ###\n",
    "dict_path = 'data/digikey_part_dictionary.csv'\n",
    "part_dict_matcher = DictionaryMatch(d=get_digikey_parts_set(dict_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use user-defined functions to further improve our matchers. For example, here we use patterns in the document filenames as a signal for whether a span of text in a document is a valid transistor part number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "\n",
    "def common_prefix_length_diff(str1, str2):\n",
    "    for i in range(min(len(str1), len(str2))):\n",
    "        if str1[i] != str2[i]:\n",
    "            return min(len(str1), len(str2)) - i\n",
    "    return 0\n",
    "\n",
    "def part_file_name_conditions(attr):\n",
    "    file_name = attr.sentence.document.name\n",
    "    if len(file_name.split('_')) != 2: return False\n",
    "    if attr.get_span()[0] == '-': return False\n",
    "    name = attr.get_span().replace('-', '')\n",
    "    return any(char.isdigit() for char in name) and any(char.isalpha() for char in name) and common_prefix_length_diff(file_name.split('_')[1], name) <= 2\n",
    "\n",
    "add_rgx = '^[A-Z0-9\\-]{5,15}$'\n",
    "\n",
    "part_file_name_lambda_matcher = LambdaFunctionMatcher(func=part_file_name_conditions)\n",
    "part_file_name_matcher = Intersect(RegexMatchSpan(rgx=add_rgx, longest_match_only=True), part_file_name_lambda_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can union all of these matchers together to form our final part matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_matcher = Union(part_rgx_matcher, part_dict_matcher, part_file_name_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emitter - Base Voltage Matchers\n",
    "\n",
    "Our emitter base voltage matcher can be a very simple regular expression\n",
    "since we know that we are looking for floats (e.g. 4.0, 5.0, 6.0), and by inspecting a portion of\n",
    "our corpus, we see that emitter base voltages fall within a fairly\n",
    "narrow range. (i.e. `4.0`,`5.0`,`6.0`,`7.0`, up to `10`)\n",
    "\n",
    "The matcher used below is from https://github.com/fonduer-apps/snorkel/blob/semi-structured/tutorials/tables/deprecated/eb_v_max.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: This is super specific. Came from previously defined snorkel matchers at https://github.com/fonduer-apps/snorkel/blob/semi-structured/tutorials/tables/deprecated/eb_v_max.ipynb\n",
    "eb_voltage_matcher = RegexMatchSpan(rgx=r'\\-?([56]|12)(\\.0)?', longest_match_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Mention's `MentionSpace`\n",
    "\n",
    "Next, in order to define the \"space\" of all mentions that are even considered\n",
    "from the document, we need to define a `MentionSpace` for each component of the\n",
    "relation we wish to extract. Fonduer provides a default `MentionSpace` for you\n",
    "to use, but you can also extend the default `MentionSpace` depending on your\n",
    "needs.\n",
    "\n",
    "In the case of transistor part numbers, the `MentionSpace` can be quite complex\n",
    "due to the need to handle implicit part numbers that are implied in text like\n",
    "\"BC546A/B/C...BC548A/B/C\", which refers to 9 unique part numbers. To handle\n",
    "these, we consider all n-grams up to 3 words long.\n",
    "\n",
    "In contrast, the `MentionSpace` for temperature values is simpler: we only need\n",
    "to process different Unicode representations of a (`-`), and don't need to look\n",
    "at more than two words at a time.\n",
    "\n",
    "When no special preprocessing like this is needed, we could have used the\n",
    "default `Ngrams` class provided by `fonduer`. For example, if we were looking\n",
    "to match polarities, which only take the form of \"NPN\" or \"PNP\", we could've\n",
    "used `ngrams = MentionNgrams(n_max=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hardware_spaces import MentionNgramsPart, MentionNgramsVolt\n",
    "\n",
    "part_ngrams = MentionNgramsPart(parts_by_doc=None, n_max=3)\n",
    "eb_voltage_ngrams = MentionNgramsVolt(n_max=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Mention Extraction \n",
    "\n",
    "Next, we create a `MentionExtractor` to extract the mentions from all of\n",
    "our documents based on the `MentionSpace` and matchers we defined above.\n",
    "\n",
    "View the API for the MentionExtractor on [ReadTheDocs](https://fonduer.readthedocs.io/en/latest/user/candidates.html#fonduer.candidates.MentionExtractor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import MentionExtractor \n",
    "\n",
    "mention_extractor = MentionExtractor(\n",
    "    session, [Part, EBVoltage], [part_ngrams, eb_voltage_ngrams], [part_matcher, eb_voltage_matcher]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we run the extractor on all of our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.candidates.mentions - Clearing table: part\n",
      "[INFO] fonduer.candidates.mentions - Clearing table: eb_voltage\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcadd1789164be89d1eb9efde1ee69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mention_extractor.apply(docs, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mentions: 4075\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates.models import Mention\n",
    "\n",
    "print(f\"Total Mentions: {session.query(Mention).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Candidate Extraction\n",
    "\n",
    "Now that we have both defined and extracted the Mentions that can be used to compose Candidates, we are ready to move on to extracting Candidates. Like we did with the Mentions, we first define what each candidate schema looks like. In this example, we create a candidate that is composed of a `Part` and a `EB_Voltage` mention as we defined above. We name this candidate \"PartEBVoltage\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import candidate_subclass\n",
    "\n",
    "PartEBVoltage = candidate_subclass(\"PartEBVoltage\", [Part, EBVoltage])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Note:\n",
    "Define mention and candidate variable names without underscores or you'll get something weird like this happen:\n",
    "> The name of the second candidate attribute is not `eb_voltage`, but it is `eb__voltage` with **two** underscores. Why is that though? It was always defined with only one underscore...\n",
    "\n",
    "It seems that Fonduer will automatically add an underscore for you... I'm still not sure why or where, but it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.attributes.InstrumentedAttribute at 0x7f48d48072b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartEBVoltage.part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.attributes.InstrumentedAttribute at 0x7f48d4807570>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartEBVoltage.eb_voltage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining candidate `Throttlers`\n",
    "\n",
    "Here, we create a throttler that discards candidates if they are in the same table, but the part and max emitter base voltage are not vertically or horizontally aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.data_model_utils import *\n",
    "import re\n",
    "\n",
    "def eb_voltage_filter(c):\n",
    "    (part, attr) = c\n",
    "    if same_table((part, attr)):\n",
    "        return (is_horz_aligned((part, attr)) or is_vert_aligned((part, attr)))\n",
    "    return True\n",
    "\n",
    "eb_voltage_throttler = eb_voltage_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the `CandidateExtractor`\n",
    "\n",
    "Now, we have all the component necessary to perform candidate extraction. We have defined the Mentions that compose each candidate and a throttler to prunes away excess candidates. We now can define the `CandidateExtractor` with the candidate subclass and corresponding throttler to use.\n",
    "\n",
    "View the API for the CandidateExtractor on [ReadTheDocs](https://fonduer.readthedocs.io/en/docstrings/user/candidates.html#fonduer.candidates.CandidateExtractor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import CandidateExtractor\n",
    "\n",
    "\n",
    "candidate_extractor = CandidateExtractor(session, [PartEBVoltage], throttlers=[eb_voltage_throttler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.candidates.candidates - Clearing table part_eb_voltage (split 0)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0a52abd3ed4da7881265d84e3c78e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Candidates in split=0: 75725\n",
      "[INFO] fonduer.candidates.candidates - Clearing table part_eb_voltage (split 1)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3823a1e3ee3a47e0a2ae1d259e98de88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Candidates in split=1: 2149\n",
      "[INFO] fonduer.candidates.candidates - Clearing table part_eb_voltage (split 2)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ed7e598cb6461e9ccd407cf86acf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Candidates in split=2: 3295\n"
     ]
    }
   ],
   "source": [
    "for i, docs in enumerate([train_docs, dev_docs, test_docs]):\n",
    "    candidate_extractor.apply(docs, split=i, parallelism=PARALLEL)\n",
    "    print(f\"Number of Candidates in split={i}: {session.query(PartEBVoltage).filter(PartEBVoltage.split == i).count()}\")\n",
    "\n",
    "train_cands = candidate_extractor.get_candidates(split = 0)\n",
    "dev_cands = candidate_extractor.get_candidates(split = 1)\n",
    "test_cands = candidate_extractor.get_candidates(split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Candidates: 81169\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates.models import Candidate\n",
    "\n",
    "print(\"Total Candidates: {}\".format(session.query(Candidate).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Multimodal Featurization\n",
    "Unlike dealing with plain unstructured text, `Fonduer` deals with richly formatted data, and consequently featurizes each candidate with a baseline library of multimodal features. \n",
    "\n",
    "### Featurize with `Fonduer`'s optimized Postgres Featurizer\n",
    "We now annotate the candidates in our training, dev, and test sets with features. The `Featurizer` provided by `Fonduer` allows this to be done in parallel to improve performance.\n",
    "\n",
    "View the API provided by the `Featurizer` on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/features.html#fonduer.features.Featurizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.features.featurizer - Clearing Features (split 0)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8c5f6884e04693983828acead1593b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1.95 s, sys: 317 ms, total: 2.27 s\n",
      "Wall time: 12min 40s\n",
      "CPU times: user 1min 29s, sys: 4.29 s, total: 1min 33s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "from fonduer.features import Featurizer\n",
    "\n",
    "featurizer = Featurizer(session, [PartEBVoltage])\n",
    "%time featurizer.apply(split=0, train=True, parallelism=PARALLEL)\n",
    "%time F_train = featurizer.get_feature_matrices(train_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75725, 28748)\n",
      "[INFO] fonduer.features.featurizer - Clearing Features (split 1)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9274c752704427ad1d9fca26dfaef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1.59 s, sys: 844 ms, total: 2.43 s\n",
      "Wall time: 9.16 s\n",
      "CPU times: user 2.95 s, sys: 123 ms, total: 3.07 s\n",
      "Wall time: 4.87 s\n",
      "(2149, 28748)\n"
     ]
    }
   ],
   "source": [
    "print(F_train[0].shape)\n",
    "%time featurizer.apply(split=1, parallelism=PARALLEL)\n",
    "%time F_dev = featurizer.get_feature_matrices(dev_cands)\n",
    "print(F_dev[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.features.featurizer - Clearing Features (split 2)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd93f5e4b254356b9b68fccc0308f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 422 ms, sys: 570 ms, total: 992 ms\n",
      "Wall time: 13.4 s\n",
      "CPU times: user 4.46 s, sys: 165 ms, total: 4.62 s\n",
      "Wall time: 7.01 s\n",
      "(3295, 28748)\n"
     ]
    }
   ],
   "source": [
    "%time featurizer.apply(split=2, parallelism=PARALLEL)\n",
    "%time F_test = featurizer.get_feature_matrices(test_cands)\n",
    "print(F_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this phase, `Fonduer` has generated the set of candidates and the feature matrix. Note that Phase 1 and 2 are relatively static and typically are only executed once during the KBC process.\n",
    "\n",
    "# Phase 3: Probabilistic Relation Classification\n",
    "In this phase, `Fonduer` applies user-defined **labeling functions**, which express various heuristics, patterns, and [weak supervision](http://hazyresearch.github.io/snorkel/blog/weak_supervision.html) strategies to label our data, to each of the candidates to create a label matrix that is used by our data programming engine.\n",
    "\n",
    "In the wild, hand-labeled training data is rare and expensive. A common scenario is to have access to tons of unlabeled training data, and have some idea of how to label them programmatically. For example:\n",
    "* We may be able to think of text patterns that would indicate a part and polarity mention are related, for example the word \"temperature\" appearing between them.\n",
    "* We may have access to an external knowledge base that lists some pairs of parts and polarities, and can use these to noisily label some of our mention pairs.\n",
    "Our labeling functions will capture these types of strategies. We know that these labeling functions will not be perfect, and some may be quite low-quality, so we will model their accuracies with a generative model, which `Fonduer` will help us easily apply.\n",
    "\n",
    "Using data programming, we can then train machine learning models to learn which features are the most important in classifying candidates.\n",
    "\n",
    "### Loading Gold Data\n",
    "For convenience in error analysis and evaluation, we have already annotated the dev and test set for this tutorial, and we'll now load it using an externally-defined helper function. If you're interested in the example implementation details, please see the script we now load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 81169 candidate labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2417761a4b4643ddbffff170ca1b8035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=81169), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GoldLabels created: 81169\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "gold_file = 'data/hardware_tutorial_gold.csv'\n",
    "load_hardware_labels(session, PartEBVoltage, gold_file, ATTRIBUTE ,annotator_name='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Functions\n",
    "\n",
    "Below is a list of patterns that I've noticed in various datasheets:\n",
    "- The emitter base voltage symbol (found in the same row as `EB_Voltage`) is usually the following: <sup>V</sup>EBO\n",
    "- The `EB_Voltage` is also often found in the same row as a V (indicating voltage).\n",
    "\n",
    "The labeling functions defined below are also from an old Snorkel [repos](https://github.com/fonduer-apps/snorkel/blob/semi-structured/tutorials/tables/deprecated/eb_v_max.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables to make code more readable\n",
    "\n",
    "ABSTAIN = 0\n",
    "FALSE = 1\n",
    "TRUE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Labeling Functions\n",
    "\n",
    "Below I run a series of experiments and tests to ensure that my labeling functions are all working properly before running them on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = session.query(PartEBVoltage).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.data_model_utils import *\n",
    "\n",
    "# Helpers\n",
    "def set_all_in_set(a, b):\n",
    "    '''return true if all of a is in b'''\n",
    "    return b.issuperset(a)\n",
    "\n",
    "def set_none_in_set(a, b):\n",
    "    '''return true if none of a is in b'''\n",
    "    return (b.difference(a) == b)\n",
    "\n",
    "def set_any_in_set(a, b):\n",
    "    '''return true if any of a is in b'''\n",
    "    return len(b.intersection(a)) > 0\n",
    "\n",
    "LFs = []\n",
    "\n",
    "###################################################################\n",
    "# POSITIVE\n",
    "###################################################################\n",
    "\n",
    "def LF_voltage_inside_table(c):\n",
    "    return TRUE if c.eb_voltage.context.sentence.is_tabular() is not None else ABSTAIN\n",
    "LFs.append(LF_voltage_inside_table)\n",
    "\n",
    "# def LF_part_is_aligned(c):\n",
    "#     return TRUE if (c.part.parent.table == c.eb_voltage.parent.table and\n",
    "#                 (c.part.parent.row_num == c.eb_voltage.parent.row_num or\n",
    "#                  c.part.parent.col_num == c.eb_voltage.parent.col_num)) else ABSTAIN\n",
    "# LFs.append(LF_part_is_aligned)\n",
    "    \n",
    "def LF_eb_keywords(c):\n",
    "    individuals = set(['emitter', 'base', 'voltage'])\n",
    "    together = set(['emitter-base', 'voltage'])\n",
    "    if c.eb_voltage.context.sentence.is_tabular() is not None:\n",
    "        row_ngrams = set(x.replace(' ', '') for x in get_row_ngrams(c.eb_voltage, lower=True) if x)\n",
    "        if set_all_in_set(individuals, row_ngrams):\n",
    "            return TRUE\n",
    "        if set_all_in_set(together, row_ngrams):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "LFs.append(LF_eb_keywords)\n",
    "\n",
    "def LF_eb_symbols(c):\n",
    "    pos_keys = set(['v ebo', 'ebo', 'vebo', 'value', 'rating'])\n",
    "    ngrams = set(get_row_ngrams(c.eb_voltage, lower=True))\n",
    "    if set_any_in_set(pos_keys, ngrams):\n",
    "        return TRUE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "LFs.append(LF_eb_symbols)\n",
    "\n",
    "def LF_low_table_num(c):\n",
    "    if c.eb_voltage.context.sentence.table is not None:\n",
    "        if c.eb_voltage.context.sentence.table.position <= 2:\n",
    "            return TRUE\n",
    "        else:\n",
    "            return FALSE\n",
    "    return ABSTAIN\n",
    "LFs.append(LF_low_table_num)\n",
    "\n",
    "def LF_whole_phrase_in_row(c):\n",
    "    row_ngrams = set(get_row_ngrams(c.eb_voltage, lower=True))\n",
    "    if 'emitter-base voltage' in row_ngrams:\n",
    "        return TRUE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "LFs.append(LF_whole_phrase_in_row)\n",
    "\n",
    "def LF_pos_units_in_row(c):\n",
    "    row_ngrams = set(get_row_ngrams(c.eb_voltage, lower=True))\n",
    "    units = set(['v', 'V'])\n",
    "    if set_any_in_set(units,row_ngrams):\n",
    "        return TRUE\n",
    "    return ABSTAIN\n",
    "LFs.append(LF_pos_units_in_row)\n",
    "\n",
    "###################################################################\n",
    "# NEGATIVE\n",
    "###################################################################\n",
    "\n",
    "def LF_specific_neg_row_keywords(c):\n",
    "    left_ngrams = set(get_row_ngrams(c.eb_voltage, lower=True))\n",
    "    neg_keys = set(['continuous', 'dc', 'cut-off'])\n",
    "    if set_any_in_set(neg_keys, left_ngrams):\n",
    "        return FALSE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "LFs.append(LF_specific_neg_row_keywords)\n",
    "\n",
    "def LF_equals_in_row(c):\n",
    "    row_ngrams = set(get_row_ngrams(c.eb_voltage))\n",
    "    if '=' in row_ngrams:\n",
    "        return FALSE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "LFs.append(LF_equals_in_row)\n",
    "\n",
    "def LF_i_in_row(c):\n",
    "    row_ngrams = set(get_row_ngrams(c.eb_voltage))\n",
    "    if 'i' in row_ngrams:\n",
    "        return FALSE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "LFs.append(LF_i_in_row)\n",
    "\n",
    "def LF_first_row(c):\n",
    "    if c.eb_voltage.context.sentence.row_start == 0:\n",
    "        return FALSE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "LFs.append(LF_first_row)\n",
    "    \n",
    "def LF_not_eb_relevant(c):\n",
    "    eb_keywords = set(['emitter', 'base', 'emitter-base'])\n",
    "    ngrams = set(get_aligned_ngrams(c.eb_voltage))\n",
    "    if not set_any_in_set(eb_keywords, ngrams):\n",
    "        return FALSE\n",
    "    else:\n",
    "        return TRUE\n",
    "LFs.append(LF_not_eb_relevant)\n",
    "\n",
    "def LF_too_many_numbers_row(c):\n",
    "    num_numbers = list(get_row_ngrams(c.eb_voltage, attrib=\"ner_tags\")).count('number')\n",
    "    return FALSE if num_numbers >= 4 else ABSTAIN\n",
    "LFs.append(LF_too_many_numbers_row)\n",
    "\n",
    "def LF_negative_keywords(c):\n",
    "    row_neg_keys = set(['ambient',\n",
    "                    'small-signal',\n",
    "                    'cut-off',\n",
    "                    'na',\n",
    "                    'ma',\n",
    "                    'cex',\n",
    "                    'resistance',\n",
    "                    'power',\n",
    "                    'junction',\n",
    "                    'dissipation', \n",
    "                    'breakdown',\n",
    "                    'current',\n",
    "                    'cbo',\n",
    "                    'vcbo'\n",
    "                    'peak',\n",
    "                    '=',\n",
    "                    'f',\n",
    "                    'p',\n",
    "                    'collector',\n",
    "                    'mw',\n",
    "                    'ceo',\n",
    "                    'vceo',\n",
    "                    'i c',\n",
    "                    'total',\n",
    "                    'device',\n",
    "                    'c',\n",
    "                    'mhz',\n",
    "                    'temperature',\n",
    "                    'saturation',\n",
    "                    'operating',\n",
    "                    'storage'\n",
    "                    'bandwidth',\n",
    "                    'derate',\n",
    "                    'above',\n",
    "                    'product',\n",
    "                    'figure',\n",
    "                    'conditions',\n",
    "                    'current gain',\n",
    "                    'saturation',\n",
    "                    'min',\n",
    "                    'min.',\n",
    "                    'typ',\n",
    "                    'typ.',\n",
    "                    'max',\n",
    "                    'max.',\n",
    "                    'gain',\n",
    "                    'p',\n",
    "                    'thermal',\n",
    "                    'test'])\n",
    "    row_ngrams = set(get_row_ngrams(c.eb_voltage))\n",
    "    col_ngrams = set(get_col_ngrams(c.eb_voltage))\n",
    "    col_neg_keys = set(['conditions', \n",
    "                        'condition', \n",
    "                        'parameter', \n",
    "                        'min',\n",
    "                        'min.',\n",
    "                        'typ',\n",
    "                        'typ.',\n",
    "                        'max',\n",
    "                        'max.',\n",
    "                        'test'])\n",
    "    if set_any_in_set(row_neg_keys, row_ngrams):\n",
    "        return FALSE\n",
    "    if set_any_in_set(col_neg_keys, col_ngrams):\n",
    "        return FALSE\n",
    "    \n",
    "    return ABSTAIN\n",
    "\n",
    "LFs.append(LF_negative_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.meta - Connecting user:nchiang to localhost:5432/eb_v_max\n",
      "[INFO] fonduer.meta - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from fonduer import Meta\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the Labeling Functions\n",
    "\n",
    "Next, we need to actually run the LFs over all of our training candidates, producing a set of `Labels` and `LabelKeys` (just the names of the LFs) in the database. Note that this will delete any existing `Labels` and `LabelKeys` for this candidate set.\n",
    "\n",
    "View the API provided by the `Labeler` on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/supervision.html#fonduer.supervision.Labeler).\n",
    "## *Note:\n",
    "I always seem to get the error shown below whenever I try to run the `Labeler` more than once in one kernel. I have always had to restart the kernel (and thus rerun everything above) to be able to run the `Labeler` without getting another one of the same error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.supervision.labeler - Clearing Labels (split 0)\n",
      "[INFO] fonduer.utils.udf - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037f30bab25a4ad7833f6a9f5d9ed44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3.32 s, sys: 599 ms, total: 3.92 s\n",
      "Wall time: 10min 10s\n",
      "CPU times: user 1min 35s, sys: 4.49 s, total: 1min 39s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "from fonduer.supervision import Labeler\n",
    "\n",
    "labeler = Labeler(session, [PartEBVoltage])\n",
    "%time labeler.apply(split=0, lfs=[LFs], train=True, parallelism=PARALLEL)\n",
    "%time L_train = labeler.get_label_matrices(train_cands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view statistics about the resulting label matrix.\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for.\n",
    "\n",
    "In addition, because we have already loaded the gold labels, we can view the emperical accuracy of these labeling functions when compared to our gold labels using the `analysis` module of [MeTaL](https://github.com/HazyResearch/metal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.supervision import get_gold_labels\n",
    "L_gold_train = get_gold_labels(session, train_cands, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_eb_keywords)</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>2147</td>\n",
       "      <td>1401</td>\n",
       "      <td>0.605130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_equals_in_row)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>8194</td>\n",
       "      <td>3615</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_first_row)</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031694</td>\n",
       "      <td>0.031694</td>\n",
       "      <td>0.031694</td>\n",
       "      <td>2043</td>\n",
       "      <td>357</td>\n",
       "      <td>0.851250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_i_in_row)</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>0.402985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_low_table_num)</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.571463</td>\n",
       "      <td>0.571463</td>\n",
       "      <td>0.538528</td>\n",
       "      <td>16858</td>\n",
       "      <td>26416</td>\n",
       "      <td>0.389564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_negative_keywords)</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386979</td>\n",
       "      <td>0.386979</td>\n",
       "      <td>0.386979</td>\n",
       "      <td>24774</td>\n",
       "      <td>4530</td>\n",
       "      <td>0.845414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_not_eb_relevant)</th>\n",
       "      <td>6</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967065</td>\n",
       "      <td>59596</td>\n",
       "      <td>16129</td>\n",
       "      <td>0.787006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_pos_keywords_in_row)</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035378</td>\n",
       "      <td>0.035378</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>1167</td>\n",
       "      <td>1512</td>\n",
       "      <td>0.435610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_specific_neg_row_keywords)</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>1267</td>\n",
       "      <td>181</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelKey (LF_voltage_inside_table)</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967065</td>\n",
       "      <td>12491</td>\n",
       "      <td>63234</td>\n",
       "      <td>0.164952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         j Polarity  Coverage  Overlaps  \\\n",
       "LabelKey (LF_eb_keywords)                0        2  0.046854  0.046854   \n",
       "LabelKey (LF_equals_in_row)              1        1  0.155946  0.155946   \n",
       "LabelKey (LF_first_row)                  2        1  0.031694  0.031694   \n",
       "LabelKey (LF_i_in_row)                   3        1  0.000885  0.000885   \n",
       "LabelKey (LF_low_table_num)              4   [1, 2]  0.571463  0.571463   \n",
       "LabelKey (LF_negative_keywords)          5        1  0.386979  0.386979   \n",
       "LabelKey (LF_not_eb_relevant)            6   [1, 2]  1.000000  1.000000   \n",
       "LabelKey (LF_pos_keywords_in_row)        7        2  0.035378  0.035378   \n",
       "LabelKey (LF_specific_neg_row_keywords)  8        1  0.019122  0.019122   \n",
       "LabelKey (LF_voltage_inside_table)       9        2  1.000000  1.000000   \n",
       "\n",
       "                                         Conflicts  Correct  Incorrect  \\\n",
       "LabelKey (LF_eb_keywords)                 0.028445     2147       1401   \n",
       "LabelKey (LF_equals_in_row)               0.155946     8194       3615   \n",
       "LabelKey (LF_first_row)                   0.031694     2043        357   \n",
       "LabelKey (LF_i_in_row)                    0.000885       27         40   \n",
       "LabelKey (LF_low_table_num)               0.538528    16858      26416   \n",
       "LabelKey (LF_negative_keywords)           0.386979    24774       4530   \n",
       "LabelKey (LF_not_eb_relevant)             0.967065    59596      16129   \n",
       "LabelKey (LF_pos_keywords_in_row)         0.002443     1167       1512   \n",
       "LabelKey (LF_specific_neg_row_keywords)   0.019122     1267        181   \n",
       "LabelKey (LF_voltage_inside_table)        0.967065    12491      63234   \n",
       "\n",
       "                                         Emp. Acc.  \n",
       "LabelKey (LF_eb_keywords)                 0.605130  \n",
       "LabelKey (LF_equals_in_row)               0.693878  \n",
       "LabelKey (LF_first_row)                   0.851250  \n",
       "LabelKey (LF_i_in_row)                    0.402985  \n",
       "LabelKey (LF_low_table_num)               0.389564  \n",
       "LabelKey (LF_negative_keywords)           0.845414  \n",
       "LabelKey (LF_not_eb_relevant)             0.787006  \n",
       "LabelKey (LF_pos_keywords_in_row)         0.435610  \n",
       "LabelKey (LF_specific_neg_row_keywords)   0.875000  \n",
       "LabelKey (LF_voltage_inside_table)        0.164952  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal import analysis\n",
    "\n",
    "analysis.lf_summary(L_train[0], lf_names=labeler.get_keys(), Y=L_gold_train[0].todense().reshape(-1,).tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Generative Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other. To do so, we use [MeTaL](https://github.com/HazyResearch/metal)'s single-task label model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[E:0]\tTrain Loss: 3.587\n",
      "[E:100]\tTrain Loss: 0.065\n",
      "[E:200]\tTrain Loss: 0.029\n",
      "[E:300]\tTrain Loss: 0.029\n",
      "[E:400]\tTrain Loss: 0.029\n",
      "[E:499]\tTrain Loss: 0.029\n",
      "Finished Training\n",
      "CPU times: user 1.98 s, sys: 10.9 ms, total: 1.99 s\n",
      "Wall time: 366 ms\n"
     ]
    }
   ],
   "source": [
    "from metal.label_model import LabelModel\n",
    "\n",
    "gen_model = LabelModel(k=2)\n",
    "%time gen_model.train_model(L_train[0], n_epochs=500, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates to get the noise-aware training label set. We'll refer to these as the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.predict_proba(L_train[0])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the distribution of the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the learned accuracy parameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75725, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen_model.weights.lf_accuracy\n",
    "L_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Using the Model to Iterate on Labeling Functions\n",
    "\n",
    "Now that we have learned the generative model, we can stop here and use this to potentially debug and/or improve our labeling function set. First, we apply the LFs to our development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler.apply(split=1, lfs=[LFs], parallelism=PARALLEL)\n",
    "%time L_dev = labeler.get_label_matrices(dev_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_dev[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Generative Model Performance\n",
    "\n",
    "At this point, we should be getting an F1 score of around 0.6 to 0.7 on the development set, which is pretty good! However, we should be very careful in interpreting this. Since we developed our labeling functions using this development set as a guide, and our generative model is composed of these labeling functions, we expect it to score very well here!\n",
    "\n",
    "In fact, it is probably somewhat overfit to this set. However this is fine, since in the next, we'll train a more powerful end extraction model which will generalize beyond the development set, and which we will evaluate on a blind test set (i.e. one we never looked at during development).\n",
    "\n",
    "\n",
    "### Training the Discriminative Model\n",
    "\n",
    "Now, we'll use the noisy training labels we generated in the last part to train our end extraction model. For this tutorial, we will be training a simple--but fairly effective--logistic regression model.\n",
    "\n",
    "We use the training marginals to train a discriminative model that classifies each Candidate as a true or false mention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.learning import LogisticRegression\n",
    "\n",
    "disc_model = LogisticRegression()\n",
    "%time disc_model.train((train_cands[0], F_train[0]), train_marginals, n_epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the Test Set\n",
    "In this final section, we'll get the score we've been after: the performance of the extraction model on the blind test set (split 2). First, we load the test set labels and gold candidates from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hardware_utils import entity_level_f1\n",
    "import pickle\n",
    "pickle_file = 'data/parts_by_doc_dict.pkl'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    parts_by_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Now, we score using the discriminitive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = disc_model.predictions((test_cands[0], F_test[0]), b=0.6)\n",
    "true_pred = [test_cands[0][_] for _ in np.nditer(np.where(test_score > 0))]\n",
    "%time (TP, FP, FN) = entity_level_f1(true_pred, gold_file, ATTRIBUTE, test_docs, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4:  Error Analysis & Iterative KBC\n",
    "\n",
    "During the development process, we can iteratively improve the quality of our labeling functions through error analysis, without executing the full pipeline as in previous techniques. \n",
    "\n",
    "You may have noticed that our final score is about 50 F1 points. To remedy this and improve our quality, we can perform error analysis to understand what kinds of patterns we may have missed, or what issues exist with our labeling functions. Then, we can edit our set of labeling functions and rerun Phase 3, Probabilistic Relation Classification. \n",
    "\n",
    "## Error Analysis\n",
    "For example, notice that our `entity_level_f1` returns `TP`, `FP`, `FN` sets. We can also see that our recall is high, but we have low precision, so let's look at our false positivies, `FP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are actually only a few documents that are causing us problems. In particular, we see that `BC546-D` is giving us many false positives. So, let's inspect one of those candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.visualizer import Visualizer\n",
    "from hardware_utils import entity_to_candidates\n",
    "vis = Visualizer(pdf_path)\n",
    "\n",
    "# Get a list of candidates that match the FN[10] entity\n",
    "fp_cands = entity_to_candidates(FP[10], test_cands[0])\n",
    "# Display a candidate\n",
    "vis.display_candidates([fp_cands[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the candidates are boxed in blue. We see that the temperature falls within the range of numbers that our matcher for storage temperature allows to match. By inspecting candidates like this, or just by examining the problematic PDFs directly, we can notice some patterns that we can exploit as new labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of candidates that match the FN[10] entity\n",
    "fp_cands = entity_to_candidates(FP[2], test_cands[0])\n",
    "\n",
    "# # Display this candidate\n",
    "vis.display_candidates([fp_cands[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively Improving Labeling Functions\n",
    "\n",
    "From this error analysis, we may notice two important things. First, our original set of labeling functions had no labeling functions that labeled candidates a negative. This resulted in most skewing the models to accept most candidates, and hurt our precision. Second, we have now noticed that we need to focus on negatively labeling numbers that pass through our storage temperature matchers, but are not related to storage temperature.\n",
    "\n",
    "Below are a set of negative labeling functions that capture some of these patterns. For example, we label candidates an negative if the number is aligned with attributes that are not related to storage temperature, if a candidate represents a typical value, rather than a maximum value, if a temperature value is found outside of a table, and other intuitive patterns we noticed when carefully inspecting our false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def LF_test_condition_aligned(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if overlap([\"test\", \"condition\"], list(get_aligned_ngrams(c.temp)))\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_collector_aligned(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if overlap(\n",
    "            [\"collector\", \"collector-current\", \"collector-base\", \"collector-emitter\"],\n",
    "            list(get_aligned_ngrams(c.temp)),\n",
    "        )\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_current_aligned(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if overlap([\"current\", \"dc\", \"ic\"], list(get_aligned_ngrams(c.temp)))\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_voltage_row_temp(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if overlap(\n",
    "            [\"voltage\", \"cbo\", \"ceo\", \"ebo\", \"v\"], list(get_aligned_ngrams(c.temp))\n",
    "        )\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_voltage_row_part(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if overlap(\n",
    "            [\"voltage\", \"cbo\", \"ceo\", \"ebo\", \"v\"], list(get_aligned_ngrams(c.temp))\n",
    "        )\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_typ_row(c):\n",
    "    return FALSE if overlap([\"typ\", \"typ.\"], list(get_row_ngrams(c.temp))) else ABSTAIN\n",
    "\n",
    "\n",
    "def LF_complement_left_row(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if (\n",
    "            overlap(\n",
    "                [\"complement\", \"complementary\"],\n",
    "                chain.from_iterable(\n",
    "                    [get_row_ngrams(c.part), get_left_ngrams(c.part, window=10)]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_too_many_numbers_row(c):\n",
    "    num_numbers = list(get_row_ngrams(c.temp, attrib=\"ner_tags\")).count(\"number\")\n",
    "    return FALSE if num_numbers >= 3 else ABSTAIN\n",
    "\n",
    "\n",
    "def LF_temp_on_high_page_num(c):\n",
    "    return FALSE if c.temp.context.get_attrib_tokens(\"page\")[0] > 2 else ABSTAIN\n",
    "\n",
    "\n",
    "def LF_temp_outside_table(c):\n",
    "    return FALSE if not c.temp.context.sentence.is_tabular() is None else ABSTAIN\n",
    "\n",
    "\n",
    "def LF_not_temp_relevant(c):\n",
    "    return (\n",
    "        FALSE\n",
    "        if not overlap(\n",
    "            [\"storage\", \"temperature\", \"tstg\", \"stg\", \"ts\"],\n",
    "            list(get_aligned_ngrams(c.temp)),\n",
    "        )\n",
    "        else ABSTAIN\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then, we can add these to our list of labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_temp_lfs_2 = [\n",
    "    LF_test_condition_aligned,\n",
    "    LF_collector_aligned,\n",
    "    LF_current_aligned,\n",
    "    LF_voltage_row_temp,\n",
    "    LF_voltage_row_part,\n",
    "    LF_typ_row,\n",
    "    LF_complement_left_row,\n",
    "    LF_too_many_numbers_row,\n",
    "    LF_temp_on_high_page_num,\n",
    "    LF_temp_outside_table,\n",
    "    LF_not_temp_relevant,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And rerun labeling. Importantly, this time we use the `.update()` function to reflect the fact that we are adding new labeling functions, but do not want to throw away the computations already performed in the previous iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time labeler.update(split=0, lfs=[stg_temp_lfs_2], parallelism=PARALLEL)\n",
    "%time L_train = labeler.get_label_matrices(train_cands)\n",
    "print(L_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.lf_summary(L_train[0], lf_names=labeler.get_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can rerun probablistic relation classification, the same way we did above. We start with the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = LabelModel(k=2)\n",
    "%time gen_model.train_model(L_train[0], epochs=500, print_every=100)\n",
    "train_marginals = gen_model.predict_proba(L_train[0])[:,1]\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we rerun the discriminitive model and see that our score has improved significantly to about 80 F1 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_model = LogisticRegression()\n",
    "%time disc_model.train((train_cands[0], F_train[0]), train_marginals, n_epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = disc_model.predictions((test_cands[0], F_test[0]), b=0.6)\n",
    "true_pred = [test_cands[0][_] for _ in np.nditer(np.where(test_score > 0))]\n",
    "# tp, fp, tn, fn = disc_model.score(session, F_test, L_gold_test)\n",
    "%time (TP, FP, FN) = entity_level_f1(true_pred, gold_file, ATTRIBUTE, test_docs, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these new LFs, we've significantly improved precision and lowered our number of false positives for an F1 score of about 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
